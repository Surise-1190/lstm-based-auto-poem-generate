from torch.utils.data import random_split, DataLoader
from torch.optim.lr_scheduler import ReduceLROnPlateau
from tqdm import tqdm
import torch
import torch.nn as nn
import torch.optim as optim

from torch.utils.data import DataLoader
from tqdm import tqdm
import torch
import torch.nn as nn
import torch.optim as optim

from config import *
from data.dataset import PoemDataset
from model.lstm_model import PoetryLSTM


def train():
    print("å¼€å§‹è®­ç»ƒæ–°æ¨¡å‹...")

    # === 1. æ•°æ®é›†åˆ’åˆ†ï¼šè®­ç»ƒé›† + éªŒè¯é›† ===
    dataset = PoemDataset(DATA_PATH, SEQ_LEN)
    
    # åˆ’åˆ† 90% è®­ç»ƒï¼Œ10% éªŒè¯
    val_size = int(0.1 * len(dataset))
    train_size = len(dataset) - val_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

    vocab_size = len(dataset.words)
    print(f"è¯æ±‡è¡¨å¤§å°: {vocab_size}")
    print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_dataset)}, éªŒè¯æ ·æœ¬æ•°: {len(val_dataset)}")

    # === 2. æ„å»ºæ¨¡å‹ ===
    model = PoetryLSTM(
        vocab_size=vocab_size,
        embed_dim=EMBEDDING_DIM,
        hidden_dim=HIDDEN_DIM,
        num_layers=NUM_LAYERS
    ).to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LR)
    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)

    # === 3. æ—©åœæœºåˆ¶ ===
    best_val_loss = float('inf')
    patience_counter = 0
    patience = 15  # æœ€å¤šå®¹å¿ 15 ä¸ª epoch æ²¡æå‡

    # === 4. è®­ç»ƒå¾ªç¯ ===
    for epoch in range(EPOCHS):
        model.train()
        total_loss = 0

        # --- è®­ç»ƒé˜¶æ®µ ---
        for x, y in tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS} [Train]"):
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            output, _ = model(x)
            loss = criterion(output.reshape(-1, vocab_size), y.reshape(-1))
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        avg_train_loss = total_loss / len(train_loader)

        # --- éªŒè¯é˜¶æ®µ ---
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for x_val, y_val in val_loader:
                x_val, y_val = x_val.to(device), y_val.to(device)
                output, _ = model(x_val)
                loss = criterion(output.reshape(-1, vocab_size), y_val.reshape(-1))
                val_loss += loss.item()

        avg_val_loss = val_loss / len(val_loader)

        # --- æ‰“å°æ—¥å¿— ---
        print(f"Epoch {epoch+1}/{EPOCHS}, "
              f"Train Loss: {avg_train_loss:.4f}, "
              f"Val Loss: {avg_val_loss:.4f}")

        # --- å­¦ä¹ ç‡è°ƒåº¦ ---
        scheduler.step(avg_val_loss)

        # --- æ—©åœåˆ¤æ–­ ---
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            # åªä¿å­˜æœ€ä½³æ¨¡å‹
            torch.save(model.state_dict(), MODEL_PATH)
            print(f"âœ… æ¨¡å‹å·²ä¿å­˜ (Val Loss æ”¹è¿›: {best_val_loss:.4f})")
        else:
            patience_counter += 1
            print(f"âš ï¸ éªŒè¯æŸå¤±æœªæ”¹è¿›ï¼Œè€å¿ƒè®¡æ•°: {patience_counter}/{patience}")

        if patience_counter >= patience:
            print(f"ğŸ¯ æ—©åœè§¦å‘ï¼æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
            break

    print(f"è®­ç»ƒå®Œæˆï¼Œæœ€ç»ˆæœ€ä½³æ¨¡å‹å·²ä¿å­˜è‡³: {MODEL_PATH}")
    return model, dataset.word_to_idx, dataset.idx_to_word